{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/14858512893477_so-logo.png\" width=\"600px\">    \r\n",
    "\r\n",
    "# Catégorisez automatiquement des questions\r\n",
    "\r\n",
    "\r\n",
    "<a id=\"top\"></a>\r\n",
    "# Sommaire\r\n",
    "\r\n",
    "* [1. Process](#1)\r\n",
    "* [2. Mise en forme](#1)\r\n",
    "    * [2.1 Import](#2.1)\r\n",
    "    * [2.2 Bag of words](#2.2)\r\n",
    "    * [2.3 TF-IDF](#2.3) \r\n",
    "    * [2.4 Word2vec](#2.4)\r\n",
    "    * [2.5 Visualisation](#2.5) \r\n",
    "* [3. Approche non supervisée](#3)\r\n",
    "    * [3.1 LDA](#3.1) \r\n",
    "    * [3.2 NMF](#3.2)\r\n",
    "* [4. Approche supervisée](#4)\r\n",
    "    * [4.1 Doc2vec](#4.1) \r\n",
    "    * [4.2 SGD, Logistic regression, LinearSVC](#4.2)\r\n",
    "* [5. Installation du modèle sur API](#5)\r\n",
    "  *   [5.1 Dump](#5.1)\r\n",
    "    * [5.2 Mise en forme process](#5.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\r\n",
    "\r\n",
    "# Generic librairies\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from IPython.display import display, HTML\r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "\r\n",
    "# ML librairies\r\n",
    "from gensim import corpora, models, similarities\r\n",
    "from sklearn import metrics, decomposition, multiclass\r\n",
    "\r\n",
    "\r\n",
    "# API, model management\r\n",
    "from flask import Flask\r\n",
    "import joblib # to save and load the model\r\n",
    "\r\n",
    "# pd.set_option('display.max_column', 100)\r\n",
    "\r\n",
    "# Activate multi output\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
    "\r\n",
    "# # For jupyter NB users \r\n",
    "# # set size of window\r\n",
    "# display(HTML(data=\"\"\"\r\n",
    "# <style>\r\n",
    "#     div#notebook-container    { width: 95%; }\r\n",
    "#     div#menubar-container     { width: 65%; }\r\n",
    "#     div#maintoolbar-container { width: 99%; }\r\n",
    "# </style>\r\n",
    "# \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\r\n",
    "# 1. Process\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "Nous somme face à un problème de classification multi label.\r\n",
    "Nous cherchons pour chaque question à prédire un ou plusieurs tags.\r\n",
    "\r\n",
    "<img src=\"img/multi label class.png\" width=\"500px\">   \r\n",
    "\r\n",
    "Nous allons tout d'abord mettre en forme nos données pour les vectoriser.  \r\n",
    "Cela afin qu'elles puissent être en paramètre d'entrée des algorithmes.\r\n",
    "\r\n",
    "Puis nous tenterons une approche supervisée avant d'enchainer par une approche supervisée.  \r\n",
    "Cette dernière devrait être plus performante car elle utilisera les tags existants.\r\n",
    "\r\n",
    "<img src=\"img/process.png\" width=\"800px\">   \r\n",
    "\r\n",
    "Enfin le modèle sélectionné sera utilisé via une API, pour cela une mise en forme pour la mise en production sera nécessaire.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\r\n",
    "# 2 Mise en forme\r\n",
    "<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Sommaire</a>\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.1\"></a>\r\n",
    "## 2.1 Import\r\n",
    "\r\n",
    "Importons notre dataset et placons le dans un pandas dataframe.  \r\n",
    "Nous utiliserons les dates comme index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/data_clean.csv\"\r\n",
    "df_raw = pd.read_csv(file, index_col='CreationDate', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>Body_tok</th>\n",
       "      <th>Title_tok</th>\n",
       "      <th>Tags_tok</th>\n",
       "      <th>Text_tok</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreationDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-09-27 06:56:36</th>\n",
       "      <td>152</td>\n",
       "      <td>66955</td>\n",
       "      <td>i lately had the problem of creating add and e...</td>\n",
       "      <td>good or bad practice for dialogs in wpf with m...</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;&lt;wpf&gt;&lt;mvvm&gt;&lt;modal-dialog&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>115</td>\n",
       "      <td>['lately', 'problem', 'creating', 'add', 'edit...</td>\n",
       "      <td>['good', 'bad', 'practice', 'dialog', 'wpf', '...</td>\n",
       "      <td>['c#', '.net', 'wpf', 'mvvm', 'modal', 'dialog']</td>\n",
       "      <td>['good', 'bad', 'practice', 'dialog', 'wpf', '...</td>\n",
       "      <td>good or bad practice for dialogs in wpf with m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-11 08:55:13</th>\n",
       "      <td>147</td>\n",
       "      <td>253229</td>\n",
       "      <td>in c, are the shift operators (&lt;&lt;,&gt;&gt;) arithmet...</td>\n",
       "      <td>are the shift operators (&lt;&lt;, &gt;&gt;) arithmetic or...</td>\n",
       "      <td>&lt;c&gt;&lt;binary&gt;&lt;bit-manipulation&gt;&lt;bit-shift&gt;</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>['c', 'shift', 'operator', 'arithmetic', 'logi...</td>\n",
       "      <td>['shift', 'operator', 'arithmetic', 'logical',...</td>\n",
       "      <td>['c', 'binary', 'bit', 'manipulation', 'bit', ...</td>\n",
       "      <td>['shift', 'operator', 'arithmetic', 'logical',...</td>\n",
       "      <td>are the shift operators (&lt;&lt;, &gt;&gt;) arithmetic or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-11 10:27:22</th>\n",
       "      <td>815</td>\n",
       "      <td>576716</td>\n",
       "      <td>whenever i design a database, i always wonder ...</td>\n",
       "      <td>database, table and column naming conventions?</td>\n",
       "      <td>&lt;database&gt;&lt;database-design&gt;&lt;language-agnostic&gt;...</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>359</td>\n",
       "      <td>['whenever', 'design', 'database', 'always', '...</td>\n",
       "      <td>['database', 'table', 'column', 'naming', 'con...</td>\n",
       "      <td>['database', 'database', 'design', 'language',...</td>\n",
       "      <td>['database', 'table', 'column', 'naming', 'con...</td>\n",
       "      <td>database, table and column naming conventions?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-11 11:57:17</th>\n",
       "      <td>110</td>\n",
       "      <td>238131</td>\n",
       "      <td>is this even a valid question? i have a .net w...</td>\n",
       "      <td>how do i enable msdtc on sql server?</td>\n",
       "      <td>&lt;sql-server&gt;&lt;msdtc&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>['even', 'valid', 'question', '.net', 'window'...</td>\n",
       "      <td>['enable', 'sql', 'server']</td>\n",
       "      <td>['sql', 'server']</td>\n",
       "      <td>['enable', 'sql', 'server', 'even', 'valid', '...</td>\n",
       "      <td>how do i enable msdtc on sql server? is this e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-10 18:41:02</th>\n",
       "      <td>539</td>\n",
       "      <td>197771</td>\n",
       "      <td>what does the expression \"turing complete\" mea...</td>\n",
       "      <td>what is turing complete?</td>\n",
       "      <td>&lt;theory&gt;&lt;turing-machines&gt;&lt;turing-complete&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>['expression', 'complete', 'mean', 'give', 'si...</td>\n",
       "      <td>['complete']</td>\n",
       "      <td>['theory', 'machine', 'complete']</td>\n",
       "      <td>['complete', 'expression', 'complete', 'mean',...</td>\n",
       "      <td>what is turing complete? what does the express...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Score  ViewCount  \\\n",
       "CreationDate                            \n",
       "2010-09-27 06:56:36    152      66955   \n",
       "2008-08-11 08:55:13    147     253229   \n",
       "2008-08-11 10:27:22    815     576716   \n",
       "2008-08-11 11:57:17    110     238131   \n",
       "2008-08-10 18:41:02    539     197771   \n",
       "\n",
       "                                                                  Body  \\\n",
       "CreationDate                                                             \n",
       "2010-09-27 06:56:36  i lately had the problem of creating add and e...   \n",
       "2008-08-11 08:55:13  in c, are the shift operators (<<,>>) arithmet...   \n",
       "2008-08-11 10:27:22  whenever i design a database, i always wonder ...   \n",
       "2008-08-11 11:57:17  is this even a valid question? i have a .net w...   \n",
       "2008-08-10 18:41:02  what does the expression \"turing complete\" mea...   \n",
       "\n",
       "                                                                 Title  \\\n",
       "CreationDate                                                             \n",
       "2010-09-27 06:56:36  good or bad practice for dialogs in wpf with m...   \n",
       "2008-08-11 08:55:13  are the shift operators (<<, >>) arithmetic or...   \n",
       "2008-08-11 10:27:22     database, table and column naming conventions?   \n",
       "2008-08-11 11:57:17               how do i enable msdtc on sql server?   \n",
       "2008-08-10 18:41:02                           what is turing complete?   \n",
       "\n",
       "                                                                  Tags  \\\n",
       "CreationDate                                                             \n",
       "2010-09-27 06:56:36                <c#><.net><wpf><mvvm><modal-dialog>   \n",
       "2008-08-11 08:55:13           <c><binary><bit-manipulation><bit-shift>   \n",
       "2008-08-11 10:27:22  <database><database-design><language-agnostic>...   \n",
       "2008-08-11 11:57:17                                <sql-server><msdtc>   \n",
       "2008-08-10 18:41:02         <theory><turing-machines><turing-complete>   \n",
       "\n",
       "                     AnswerCount  CommentCount  FavoriteCount  \\\n",
       "CreationDate                                                    \n",
       "2010-09-27 06:56:36            3            12            115   \n",
       "2008-08-11 08:55:13           11             1             60   \n",
       "2008-08-11 10:27:22           23             4            359   \n",
       "2008-08-11 11:57:17            6             1             30   \n",
       "2008-08-10 18:41:02           15             1            178   \n",
       "\n",
       "                                                              Body_tok  \\\n",
       "CreationDate                                                             \n",
       "2010-09-27 06:56:36  ['lately', 'problem', 'creating', 'add', 'edit...   \n",
       "2008-08-11 08:55:13  ['c', 'shift', 'operator', 'arithmetic', 'logi...   \n",
       "2008-08-11 10:27:22  ['whenever', 'design', 'database', 'always', '...   \n",
       "2008-08-11 11:57:17  ['even', 'valid', 'question', '.net', 'window'...   \n",
       "2008-08-10 18:41:02  ['expression', 'complete', 'mean', 'give', 'si...   \n",
       "\n",
       "                                                             Title_tok  \\\n",
       "CreationDate                                                             \n",
       "2010-09-27 06:56:36  ['good', 'bad', 'practice', 'dialog', 'wpf', '...   \n",
       "2008-08-11 08:55:13  ['shift', 'operator', 'arithmetic', 'logical',...   \n",
       "2008-08-11 10:27:22  ['database', 'table', 'column', 'naming', 'con...   \n",
       "2008-08-11 11:57:17                        ['enable', 'sql', 'server']   \n",
       "2008-08-10 18:41:02                                       ['complete']   \n",
       "\n",
       "                                                              Tags_tok  \\\n",
       "CreationDate                                                             \n",
       "2010-09-27 06:56:36   ['c#', '.net', 'wpf', 'mvvm', 'modal', 'dialog']   \n",
       "2008-08-11 08:55:13  ['c', 'binary', 'bit', 'manipulation', 'bit', ...   \n",
       "2008-08-11 10:27:22  ['database', 'database', 'design', 'language',...   \n",
       "2008-08-11 11:57:17                                  ['sql', 'server']   \n",
       "2008-08-10 18:41:02                  ['theory', 'machine', 'complete']   \n",
       "\n",
       "                                                              Text_tok  \\\n",
       "CreationDate                                                             \n",
       "2010-09-27 06:56:36  ['good', 'bad', 'practice', 'dialog', 'wpf', '...   \n",
       "2008-08-11 08:55:13  ['shift', 'operator', 'arithmetic', 'logical',...   \n",
       "2008-08-11 10:27:22  ['database', 'table', 'column', 'naming', 'con...   \n",
       "2008-08-11 11:57:17  ['enable', 'sql', 'server', 'even', 'valid', '...   \n",
       "2008-08-10 18:41:02  ['complete', 'expression', 'complete', 'mean',...   \n",
       "\n",
       "                                                                  Text  \n",
       "CreationDate                                                            \n",
       "2010-09-27 06:56:36  good or bad practice for dialogs in wpf with m...  \n",
       "2008-08-11 08:55:13  are the shift operators (<<, >>) arithmetic or...  \n",
       "2008-08-11 10:27:22  database, table and column naming conventions?...  \n",
       "2008-08-11 11:57:17  how do i enable msdtc on sql server? is this e...  \n",
       "2008-08-10 18:41:02  what is turing complete? what does the express...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28077, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 28077 entries, 2010-09-27 06:56:36 to 2018-04-26 23:29:11\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Score          28077 non-null  int64 \n",
      " 1   ViewCount      28077 non-null  int64 \n",
      " 2   Body           28077 non-null  object\n",
      " 3   Title          28077 non-null  object\n",
      " 4   Tags           28077 non-null  object\n",
      " 5   AnswerCount    28077 non-null  int64 \n",
      " 6   CommentCount   28077 non-null  int64 \n",
      " 7   FavoriteCount  28077 non-null  int64 \n",
      " 8   Body_tok       28077 non-null  object\n",
      " 9   Title_tok      28077 non-null  object\n",
      " 10  Tags_tok       28077 non-null  object\n",
      " 11  Text_tok       28077 non-null  object\n",
      " 12  Text           28077 non-null  object\n",
      "dtypes: int64(5), object(8)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.head()\r\n",
    "df_raw.shape\r\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only keep the texts and the tags\r\n",
    "df = df_raw[[\"Text_tok\", \"Tags_tok\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\r\n",
    "\r\n",
    "# by default list are put in strings by pands, let's convert it to lists\r\n",
    "# ast.literal_eval il more secure than eval\r\n",
    "df[\"Text_tok\"] = df[\"Text_tok\"].apply(lambda x: ast.literal_eval(x))\r\n",
    "df[\"Tags_tok\"] = df[\"Tags_tok\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we put the text into string form, usefull for vectorizers\r\n",
    "df['Text'] = df['Text_tok'].str.join(' ')\r\n",
    "df['Tags'] = df['Tags_tok'].str.join(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.2\"></a>\r\n",
    "## 2.2 Bag of words\r\n",
    "\r\n",
    "Nous allons maintenant extraire l'information du texte pour pouvoir le traiter par des modèles de machine learning.\r\n",
    "\r\n",
    "Une représentation bag-of-words classique sera celle dans laquelle on représente chaque document par un vecteur de la taille du vocabulaire  |V|.  \r\n",
    "On utilisera la matrice composée de l’ensemble de ces N documents qui forment le corpus comme entrée de nos algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(5286 unique tokens: ['.net', 'achieved', 'add', 'anything', 'anyways']...)\n"
     ]
    }
   ],
   "source": [
    "# we create a dictionnary of the uniques words of corpus\r\n",
    "# each word will have an unique id\r\n",
    "dictionary = corpora.Dictionary(df.Text_tok)\r\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of word (sparse matrix)\r\n",
    "# return a list of tuple\r\n",
    "# first entry in each tuple corresponds to the ID of the token in the dictionary\r\n",
    "# the second corresponds to the count of this token.\r\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in df.Text_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\r\n",
    "bow_corpus[10][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3\"></a>\r\n",
    "## 2.3 TF-IDF\r\n",
    "\r\n",
    "Le modèle tf-idf transforme les vecteurs de la représentation bag of word (BOW) en vecteurs dont les fréquences ont pour poids la rareté relative de chaque mot du corpus.\r\n",
    "\r\n",
    ">La métrique tf-idf (Term-Frequency - Inverse Document Frequency) utilise comme indicateur de similarité l'inverse document frequency.  \r\n",
    ">Celui ci est est l'inverse de la proportion de document qui contient le terme, à l'échelle logarithmique.  \r\n",
    ">Il est appelé logiquement « inverse document frequency » (idf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\r\n",
    "model_tfidf = models.TfidfModel(bow_corpus)\r\n",
    "\r\n",
    "# transformation of the corpus\r\n",
    "tfidf_corpus = model_tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.4\"></a>\r\n",
    "## 2.4 word2vec\r\n",
    "\r\n",
    "Nous allons étudier un modèle de vectorisation des données : Word2vec\r\n",
    "Dans l'architecture word2vec, les 2 algorithmes utilisés sont “continuous bag of words” (cbow) et “skip-gram” (sg).\r\n",
    "\r\n",
    "Nous allons entrainer un modèle puis tester les similarités entre les mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = models.Word2Vec(sentences=df.Text_tok,\r\n",
    "window=5,\r\n",
    "min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71955204"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.12923086"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.similarity(\"numpy\", \"matplotlib\")\r\n",
    "model_w2v.wv.similarity(\"python\", \"sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que certains termes sont plus \"proches\" les uns des autres que d'autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scipy', 0.7465876340866089),\n",
       " ('opencv', 0.6286360621452332),\n",
       " ('sklearn', 0.6123313903808594),\n",
       " ('panda', 0.6084346175193787),\n",
       " ('matplotlib', 0.6011823415756226),\n",
       " ('tkinter', 0.5861979126930237),\n",
       " ('matlab', 0.5748122334480286),\n",
       " ('setuptools', 0.5679492354393005),\n",
       " ('cython', 0.5491674542427063),\n",
       " ('distutils', 0.5464653372764587)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive=['python', 'numpy', 'android'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque également que pandas a été lemmatizé en panda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpy', 0.19601266), ('matplotlib', 0.13810204), ('import', 0.11569595)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.predict_output_word(['python', 'numpy', 'matplotlib', 'android'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode prédict output word nous donne uniquement la distribution de probabilité du mot central compte tenu des mots de contexte.  \r\n",
    "Cela est une méthode \"brute\" de prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.5\"></a>\r\n",
    "## 2.5 Visualisation\r\n",
    "\r\n",
    "Visualisons les imilarités de nos données.  \r\n",
    "Pour cela nous appliquons l'algorithme TSNE afin de réduire la dimension des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f19444fd7053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mx_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_dimensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_w2v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_with_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\r\n",
    "from sklearn.manifold import TSNE                   # final reduction\r\n",
    "\r\n",
    "def reduce_dimensions(model):\r\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\r\n",
    "\r\n",
    "    # extract the words & their vectors, as numpy arrays\r\n",
    "    vectors = np.asarray(model.wv.vectors)\r\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\r\n",
    "\r\n",
    "    # reduce using t-SNE\r\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\r\n",
    "    vectors = tsne.fit_transform(vectors)\r\n",
    "\r\n",
    "    x_vals = [v[0] for v in vectors]\r\n",
    "    y_vals = [v[1] for v in vectors]\r\n",
    "    return x_vals, y_vals, labels\r\n",
    "\r\n",
    "\r\n",
    "x_vals, y_vals, labels = reduce_dimensions(model_w2v)\r\n",
    "\r\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "    import random\r\n",
    "\r\n",
    "    random.seed(0)\r\n",
    "\r\n",
    "    plt.figure(figsize=(12, 12))\r\n",
    "    plt.scatter(x_vals, y_vals, cmap='Spectral')\r\n",
    "\r\n",
    "    #\r\n",
    "    # Label randomly subsampled 25 data points\r\n",
    "    #\r\n",
    "    indices = list(range(len(labels)))\r\n",
    "    selected_indices = random.sample(indices, 25)\r\n",
    "    for i in selected_indices:\r\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\r\n",
    "    \r\n",
    "    plt.savefig('img/scatter_w2v.png', bbox_inches='tight')\r\n",
    "\r\n",
    "# plot_function(x_vals, y_vals, labels)\r\n",
    "\r\n",
    "plot_with_matplotlib(x_vals, y_vals, labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\r\n",
    "# 3. Approche non supervisée\r\n",
    "<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Sommaire</a>\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\r\n",
    "## 3.1 LDA\r\n",
    "\r\n",
    ">L’allocation de Dirichlet latente (Latent Dirichlet Allocation) ou LDA est un modèle génératif probabiliste  \r\n",
    ">permettant d’expliquer des ensembles d’observations, par le moyen de groupes non observés,  \r\n",
    ">eux-mêmes définis par des similarités de données.\r\n",
    "\r\n",
    "Nous séparerons tout d'abord notre jeu de donnée.  \r\n",
    "Puis nous les vectoriserons.  \r\n",
    "Ensuite nous choisirons les hyperparamètre de la LDA afin d'entrainer un modèle. \r\n",
    "\r\n",
    "Option :\r\n",
    "* pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_lda_train, X_lda_test, y_lda_train, y_lda_test = train_test_split(\r\n",
    "    df['Text'], df['Tags'], test_size=0.2,train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "# Sampling dataset\r\n",
    "vectorizer_tfidf = TfidfVectorizer(analyzer='word', min_df=0.0, max_df = 1.0, \r\n",
    "                                   strip_accents = None, encoding = 'utf-8', \r\n",
    "                                   preprocessor=None, \r\n",
    "                                   token_pattern=r\"(?u)\\S\\S+\", # Need to repeat token pattern\r\n",
    "                                   max_features=10000)\r\n",
    "\r\n",
    "# TF-IDF matrices\r\n",
    "X_tfidf_train = vectorizer_tfidf.fit_transform(X_lda_train)\r\n",
    "X_tfidf_test = vectorizer_tfidf.transform(X_lda_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L(w) est la log-vraisemblance des documents non vus w ; plus la perplexité est faible, meilleur est le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting term frequency features for LDA...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEWCAYAAAAgpUMxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8l0lEQVR4nO3deXwU9f348debACHcR8IVjiD3JVcEvCr1KKhV0HpAUbBiUbxbrfVo1W+trdafR20LrYpyiCIeKJ6tt7UiGAg3glGuJNz3lZDj/ftjPtHJspsDsplN8n4+HvvI7mfmM/ueye68Zz7z2c+IqmKMMcZUtlpBB2CMMaZmsgRkjDEmEJaAjDHGBMISkDHGmEBYAjLGGBMIS0DGGGMCYQkohIioiHQ5xrqni8iaio6pDO/bXUTSRWS/iNxc2e8fEkuK24a1j3M5d4vIMxUVV6w7ns9dtIjIVSLyue/1ARE5IciYYomIfCIi1wT03gki8qaI7BWRlyvh/VaKyLCKXu5x7SSCJCLrgVZAga94mqreWIkxKNBVVTMAVPW/QPfKen+fO4BPVHVAAO8dFar6p6LnIpICrAPqqGp+YEHVcKraMOgYzPcuwdv/tQj3nRCR+4EuqnpFRbyZqvauiOWEqrIJyLlAVT8IOogY0BGYHe03EREBRFULo/1eVYmI1LbEaI7VMX6vOgJrq/znTlWr5ANYD5wdpjwe2AP08ZUlAYeBlu71L4EMYBcwD2jrm1fxjhwAPgGu8U27CvjcPf/MzXsQOABcDgwDMn3z93TL2AOsBC70TZsG/AN4G9gPLAA6l7C+F7pl7HHL7OnKP8I7C8xxcXQLU/cT4M/AQmAv8AbQ3Dd9KPCFW/ZSYFhI3QeB/7lt2KWk5QEpbrvUdq+bAFOBzUAW8EcgDqgLLAFucvPFufe4172+H3jePd/olnnAPc5w/7u+vjhbuviSwqx/F+BTF+sO4CXftN7A+255W4G7fZ+jJ4Bs93gCiHfThgGZwG+BLcBMvObsO4FvgZ3AHP82DhPTb9w2yQaupvjnLh74f269twL/BBJC3vtuty7rgbEhn//S6t4GbHPv/wtf3RZ434d97n/7AO7zHua7MY0SPr/AT4A1bptPdtv/mgjboizbOmzMET7rD+B9lvYD/wES/cuKtB/B+8y9DDzv6i4HugF3uffeBPwkWt+rMOsSdv8B/B9wBMjD+z5MCKk3ImT6Ulfe1v1/d+Ht/37pq3M/8Arwklv3xUC/CNspDu/z962bdxHQHhDgcbet9gLL8O2Hw/6/KiohVPaDCAnITXsWeND3+gbgPff8TLwv7kC8D/7fgM8ifMk+IUICCp039AMO1HH/5LvxdrZnun9Wd98XeBcwGO9MdBYwO8L6dMNLdOe45d7hll03XJwRvpRZQB+gAfAqP+zck/F2mOfh7UTPca+TfHU34u2oa7v3L2l5KRRPQK8D/3LztcT7sl7rpvUBduN90e4BvgTifF+IsMt0ZZOBh32vbwHejLD+L7rl1wLqAae58kZ4O7TbXHkjYIib9gcXT0u8A5gvgAd8/+d84GG8z1ACcKubv50r+xfwYoR4RuAlh6Lt9wLFP3dP4O0omruY3gT+HPLej7n3OQPvs9G9HHX/4P6P5wGHgGZu+my8xNnAxZZFyQko7OcXSMRLYhe7abfg7QwjJaCybOuwMUf4rH+L951JcK8fCv1+htuP4H3mcoDhLu4ZeE2/97j3/iWwLlrfq5C4Stt/3F/0XhG2w1HT8Q4CJuN91vsD24GzfPPn4TXt1QFu54dm79Dt9Bu85NwdL+n0wzt4GY6XjJq68p5AmxL34xWdGCrr4TbIAbyjg6LHL920s4HvfPP+Dxjnnk8F/uKb1tBt+JQwX7JPOPYEdDre0XGtkB3h/b4v8DO+aecBX0dY198Dc3yva+F98IeFizPCl/Ih3+teeEdIcXhH8TND5v83MN5X9w/lWF6K2y618dqoc3FH4G7eMcDHvte3AV/jJaKu4b5AhE9AQ/COSGu512nAZRHWfwbwFNAupHwMkB6hzrfAeb7Xw4H1vv/zEaCeb/pq3JfZvW7jPle1wyz72ZDt163os4T3xT1I8bOJk3E7Pn7YITfwTZ/jPiNlqXs4ZDtuwztSj3Px9vBN+xMlJ6Cwn19gHDDfN03c/ypSAiptW4eNuYTP+u98r6/nh4PPYZSegN73TbsAbx9TdFDUyG2DptH4XoXMW9r+437KkYDwzlAKgEa+sj/jXTcvmv9L37RaeAdnp4fZTmuAkWHe80xgrfs81YoUm/9R1XvBjVLVpr7H0678IyBBRIaISEe8bD/XTWsLbChagKoewDsySa7g2NoCm7R4u+6GkPfZ4nt+CC8ZRlqWP+ZCvC90eWLeFBJHHbwj1Y7ApSKyp+gBnIa3Aw1Xt7Tl+XV05Zt9y/4X3pFukel4CeYdVf2mrCujqgvwdrZniEgPvJ33vAiz34G3E1zoevNc7crb4+38wim2zd3ztr7X21U1x/e6IzDXt56r8b7wrSIsO3T7FUkC6gOLfMt6z5UX2a2qB8PEVpa6O7X4dYOiz10S3kFDpLjCifT5LbZ+6u2dMktYTmnbOlLM5Y2rLLb6nh8Gdqhqge81Icur6O9VkbLsP8qjLbBLVfeXsDz//6wQ73/m/z8UCfu9UdWPgL/jNc1uFZGnRKRxSUFV9QQUltt4c/COcH8OvOXb8Nl4Hw4ARKQB3uljVphFHcT7QhdpXY4wsoH2IuLfxh0ivE9ZluWPWfA+BOVZVvuQOPLwmiI34R2p+RN5A1V9yDe/lmN5fpvwzoASfcturMV71EwG3gKGi8hpEWIP9/7gJa8rgCuBV0ISwg+VVbeo6i9VtS1wLTDZdXneBHSOsOxi29ytY3YJMW0Czg3ZjvVUNdz/aDNHb78iO/B2dL19y2mixXugNXOf29DYylI3ku14Z1aR4iqPzXhNkcD3n9d2kWcvdVtXlGLfZxGJo3hyPhYV/b0qcrz7j9BlZwPNRaRRCcv7fl3c+7Yj/P8h4vdGVZ9U1UF4TYvd8JrrIqqWCch5Aa9jwFj33F/+CxHpLyLxeM0MC1R1fZhlLAEuFpH6boc1IWT6ViDS7yKKjtDvEJE6rg/9BRxbb7U5wPkicpaI1MFrtsrFaysvqytEpJeI1MdrT3/FHdk9D1wgIsNFJE5E6onIMBEpaYdR0vK+p6qb8S4CPyoijUWkloh0FpEzAETkSmAQXtPmzcB0EQm3s9wOFHL0tp4JXISXhGZEClRELvWtz268L2cBXuJrLSK3iki8iDQSkSFuvheB34lIkogkAve6bRXJP4EH3Rk3rt7ICPPOAa7ybb/7iia4g6engcdFpKVbVrKIDA9Zxv+JSF0ROR34KfByOeoexf3vXgPud5/3XsD40upF8DbQV0RGud+D3UDJB2/l3dbHai1QT0TOd9+j3+FdRzseFf29KnK8+4+tQEpRAlPVTXj7iz+7WE7E25/N8tUZJCIXu//ZrXj7mC/DLPsZ4AER6SqeE0WkhYic5Fqd6rjYcyj+M5mjVPUE9KZ4P44rehQ1s/mbaNoC7/rKP8RrL38V70itMzA6wvIfx2vT3Yp3tD0rZPr9eDvNPSJymX+Cqh7B67l2Lt4R0WS861Bfl3clVXUN3k72b25ZF+B1QT9SjsXMxGu334J3EfJmt+xNwEi8i53b8Y5ufkPpn42wywtjHN5F1FV4O/9XgDYi0gHvgvk4VT2gqi/gXcd5PHQBqnoI12PIbeuhrjwTr7eOAv8tIdaTgAUicgCvme4WVV3nzorPwdueW4BvgB+7On908SzDu+C62JVF8le37P+IyH68L+6QcDOq6rtu3T/Cu9D8Ucgsv3XlX4rIPuADiv++bAvetszG+0xe5/tclVa3JDfiNS9twfvfPlfGesWo6g7gUuAveM3bvfC2ZW6EKuXd1sdEVffiXRN6Bu/I/yAlNw2WRUV/r4piPd79R9GPU3eKyGL3fAxec3c23iWJ+1T1fV+dN/AO2nfjtSpcrKp5YZb9GN5B1H/wOptMxevw0RjvAGg3XvPeTrwemRGJu3hkqjER+QTvgmSFjCxQ0cs7zlieBbJV9XdBx1IZ3JHw86pa1iPpwLmj8Ey87uIfBx2POZpU8A9Xy6qq/xDV1GDijZBwMVBtRoCoLlyz3wK8a1K/wesEEq45x9RgVb0JztRQIvIAsAJ4RFXXBR2POcrJeD2lipqMR6nq4ZKrmJrGmuCMMcYEws6AjDHGBKLGXQNKTEzUlJSUoMMwxpgqZdGiRTtU9Xh/N1VMjUtAKSkppKWlBR2GMcZUKSJS2sgY5Ra1JjgRaS8iH4vIavGGP7klZPrt4t2EK9FXdpeIZIjIGv+P50RkkIgsd9OedL+sxv148CVXvsD1ijLGGFMFRPMaUD5wm6r2xBuc7gb362pEpD3eDwA3Fs3spo3GG8JhBN5wKXFu8hRgItDVPUa48gl442J1wfsB48NRXB9jjDEVKGoJSFU3q+pi93w/3uCMRQPfPY43QKS/C95IvOHcc1232gxgsIi0ARqr6nw3qOEMYJSvznT3/BXgrKKzI2OMMbGtUnrBuaaxAXjDoVwIZKnq0pDZkik+OmymK0um+HAZReXF6rjRcvfiDSxqjDEmxkW9E4IbXPJVvMHt8vFu7vSTcLOGKdMSykuqExrDRLwmPDp0ONYBfo0xxlSkqJ4BuVFRXwVmqepreAN/dgKWish6vOG+F4tIa7wzG//Q5kVDgWdSfCh3/xDh39dxI7g2wbtLYzGq+pSqpqpqalJShfYiNMYYc4yi2QtO8EZJXa2qjwGo6nJVbamqKaqagpdABqrqFryRhEe7nm2d8DobLHRD+u8XkaFumePwRm3F1SkaMv4S4CO1oR2MMaZKiOYZ0Kl4Q3qfKSJL3OO8SDOr6kq8Ib5X4d3F8Qbf/WUm4Q2hnoE3vlTR7RWmAi1EJAP4NXBnVNbEGGOqsPU7DvLEB2tZu3V/6TNXoqhdA1LVzwl/jcY/T0rI6wfx7vsSOl8a0CdMeQ7efUeMMcb47Dp4hLeWZTM3PYv0jXsQgRYN4+nWqlHplStJjRsJwRhjqqucvAI+XL2NuemZfLJmO/mFSo/Wjbjr3B5c2L8tbZokBB1iMZaAjDGmCissVBas28Xc9EzeXb6F/bn5tGocz4TTOjFqQDI92zQOOsSILAEZY0wVtHbrfl5bnMW8JVlk782hQd04zu3bhosGJDP0hBbE1Yr93+RbAjLGmCpi274c5i3N5rXFWazavI+4WsKPuiZy53k9OadnKxLqxpW+kBhiCcgYY2LYwdx8/r1yC3PTs/hfxg4KFfq1a8L9F/Tip/3aktgwPugQj5klIGOMiTH5BYV8nrGD19Oz+PfKrRzOK6B98wRu/HEXRg5IpnNSw6BDrBCWgIwxJgaoKiuy9jE3PYt5S7PZcSCXJgl1uHhgMhcNSGZQx2ZUt7GWLQEZY0yANu06xLyl3u91MrYdoG5cLc7s0ZKLBiYzrHsS8bWr1nWd8rAEZIwxlWzvoTzeWbGZuYuzWLjeG75ycEpz/nRRX87v24Ym9esEHGHlsARkjDGVIDe/gE/WbOf19Cw+XL2NIwWFnJDUgNt/0o2R/ZNp37x+0CFWOktAxhgTJarKog27mZuexVvLNrP3cB6JDesydmgHLh7Qjj7JjavddZ3ysARkjDEV7LvtB3g9PYu5S7LYtOsw9erUYnjv1lw0IJnTuiRSO65S7gUa8ywBGWNMBdhxIJe3lmYzd0k2SzftoZbAqV0SufWsbgzv05qG8ba7DWVbxBhjjtHhIwW8v3orr6dn8ena7RQUKr3aNOae83pyYf+2tGpcL+gQY5olIGOMKYeCQuXL73YyNz2L91Zs4UBuPm2a1OOXp5/ARQOS6d46dm53EOssARljTBms3ryP19OzeGNJNlv25dAovjbn9W3NqAHJDO3UglpVYPDPWGMJyBhjItiyN4c3lmQxNz2Lr7fsp3YtYVj3JH73056c3bMV9epU3x+JVgZLQMYY47M/J4/3Vmzh9SVZfPHtTlRhQIem/GFkb87v24YWVXjwz1hjCcgYU+PlFRTy32+2Mzc9m/dXbSEnr5COLepz85ldGTUgmU6JDYIOsVqyBGSMqZFUlWWZe5mbnsWbS7PZefAITevX4dJB7Rk1IJmBHZrW6B+JVgZLQMaYGmXTrkPMTc/i9fQsvttxkLq1a3F2z5ZcNKAdZ3RLom5t+5FoZYlaAhKR9sAMoDVQCDylqn8VkUeAC4AjwLfAL1R1j6tzFzABKABuVtV/u/JBwDQgAXgHuEVVVUTi3XsMAnYCl6vq+mitkzGmatpz6AhvLdvM6+lZpG3YDcDQE5pz7RknMKJPG5ok1IzBP2NNNM+A8oHbVHWxiDQCFonI+8D7wF2qmi8iDwN3Ab8VkV7AaKA30Bb4QES6qWoBMAWYCHyJl4BGAO/iJavdqtpFREYDDwOXR3GdjDFVRG5+AR9/vY3XFmfx8Zpt5BUoXVs25I4R3RnZP5nkpglBh1jjRS0BqepmYLN7vl9EVgPJqvof32xfApe45yOB2aqaC6wTkQxgsIisBxqr6nwAEZkBjMJLQCOB+139V4C/i4ioqkZrvYwxsauwUEnbsJu56Zm8vWwz+3LySWoUz/iTUxg1IJnebWv24J+xplKuAYlICjAAWBAy6WrgJfc8GS8hFcl0ZXnueWh5UZ1NAO6Mai/QAtgR8v4T8c6g6NChw/GtjDEm5mRsO8Dc9ExeT88ma89hEurEMaKPN/jnKZ1b2OCfMSrqCUhEGgKvAreq6j5f+T14zXSziorCVNcSykuqU7xA9SngKYDU1FQ7OzKmGti+P5d5S7N5PT2L5Vl7qSVwWtckfjO8O+f0akUDG/wz5kX1PyQidfCSzyxVfc1XPh74KXCWr7ksE2jvq94OyHbl7cKU++tkikhtoAmwKwqrYoyJIR99vZXrZi7mSEEhfZIb87vzvcE/WzaywT+rkmj2ghNgKrBaVR/zlY8AfgucoaqHfFXmAS+IyGN4nRC6AgtVtUBE9ovIULwmvHHA33x1xgPz8a4lfWTXf4yp3r78bieTnl9MjzaNePTSfnRtZYN/VlXRPAM6FbgSWC4iS1zZ3cCTQDzwvrsY+KWqXqeqK0VkDrAKr2nuBtcDDmASP3TDftc9wEtwM12HhV14veiMMdXUssw9XDM9jQ7N6zPtF4Np3qBu0CGZ4yA17YQhNTVV09LSgg7DGFNO32zdz2X/mk+D+Nq8ct0ptG5izW2VSUQWqWpqRS7TuoYYY2Lepl2HuGLqAmrH1WLWNUMs+VQTloCMMTFt274crpi6gJy8Qp6fMISOLWxg0OrCEpAxJmbtOXSEK6cuZPv+XKb94iS722g1YwnIGBOTDubmc9VzX7Fux0GeHpfKgA7Ngg7JVDD7pZYxJubk5BUwcWYay7P2MnnsQE7tkhh0SCYK7AzIGBNT8gsKufnFdP6XsZO//OxEhvduHXRIJkosARljYkZhoXLHq8v4z6qt3H9BL342qF3plUyVZQnIGBMTVJU/vLWK1xZncds53bjq1E5Bh2SizBKQMSYmPP7BN0z7Yj3XnNaJG8/sEnQ4phJYAjLGBO6Z/37Hkx9+w+Wp7bnn/J52z54awhKQMSZQc77axB/fXs15fVvzp4v7WvKpQSwBGWMC887yzdz52jJ+1C2Jxy/vT1wtSz41iSUgY0wgPl27nVtmpzOwQzP+ecVA4mvHBR2SqWSWgIwxlW7Rhl1cN3MRXVs2YupVJ1G/rv0mviayBGSMqVSrsvdx1XNf0aZJPWZMGEyThDpBh2QCYgnIGFNpvtt+gHHPLqBRfG1mXjOExIbxQYdkAmQJyBhTKbL3HOaKZxagCjOvGUJy04SgQzIBswRkjIm6HQdyuWLqAvbn5DP96sF0TmoYdEgmBtiVP2NMVO3LyWP8swvJ3nOYmROG0Ce5SdAhmRhhZ0DGmKg5fKSACdO+Yu3W/fzzikGclNI86JBMDLEEZIyJiiP5hVz3/CIWbdjNE5cPYFj3lkGHZGJM1BKQiLQXkY9FZLWIrBSRW1x5cxF5X0S+cX+b+ercJSIZIrJGRIb7ygeJyHI37UlxY3WISLyIvOTKF4hISrTWxxhTdgWFyq9eWsKna7fz54v7cv6JbYIOycSgaJ4B5QO3qWpPYChwg4j0Au4EPlTVrsCH7jVu2migNzACmCwiRT+NngJMBLq6xwhXPgHYrapdgMeBh6O4PsaYMlBV7pm7nLeXb+ae83py+Ukdgg7JxKioJSBV3ayqi93z/cBqIBkYCUx3s00HRrnnI4HZqpqrquuADGCwiLQBGqvqfFVVYEZInaJlvQKcJTaSoTGBUVX+/O7XzP5qEzed2YVf/uiEoEMyMaxSrgG5prEBwAKglapuBi9JAUUNw8nAJl+1TFeW7J6Hlhero6r5wF6gRZj3nygiaSKStn379gpaK2NMqMmffMtTn33H+JM78utzugUdjolxUU9AItIQeBW4VVX3lTRrmDItobykOsULVJ9S1VRVTU1KSiotZGPMMZgxfz2P/HsNFw1I5r4LetttFUypopqARKQOXvKZpaqvueKtrlkN93ebK88E2vuqtwOyXXm7MOXF6ohIbaAJsKvi18QYU5K56Znc+8ZKzunVikcuOZFadlsFUwbR7AUnwFRgtao+5ps0Dxjvno8H3vCVj3Y92zrhdTZY6Jrp9ovIULfMcSF1ipZ1CfCRu05kjKkk76/ayu0vL+OUzi3425gB1I6zX3eYsonmSAinAlcCy0VkiSu7G3gImCMiE4CNwKUAqrpSROYAq/B60N2gqgWu3iRgGpAAvOse4CW4mSKSgXfmMzqK62OMCfHFtzu44YXF9EluwlPjUqlXx+7pY8pOatoJQ2pqqqalpQUdhjFV3pJNexj79JckN0tgzrUn07R+3aBDMlEkIotUNbUil2nnysaYcluzZT9XPbeQFg3jmTlhiCUfc0wsARljymXjzkNcOXUBdeNqMeuaIbRqXC/okEwVZaNhG2PKbOu+HMZO/ZIjBYXMufZk2jevH3RIpgqzMyBjTJnsPniEK55ZwK4DR5j+i8F0a9Uo6JBMFWdnQMaYUh3Izeeq5xayYdchpv9iMP3aNw06JFMN2BmQMaZEOXkFXDP9K1Zk72PyzwdycuejRrsy5phYAjLGRJRXUMiNLyxmwbpdPHppP87u1SrokEw1YgnIGBNWYaHym5eX8sHqbfzhwt6MGpBceiVjysESkDHmKKrKffNW8vqSbH4zvDtXnpwSdEimGrIEZIw5yqP/WcvMLzdw7Y9O4PphnYMOx1RTloCMMcU89dm3/P3jDMYMbs+d5/aw2yqYqLEEZIz53osLN/Knd77mpye24Y+j+lryMVFlCcgYA8CbS7O5e+5yhnVP4rHL+hNn9/QxUWYJyBjDx2u28auXlnBSx+ZMGTuIurVt12Cizz5lxtRwC9ftYtLzi+jeuhHPXJVKQl27p4+pHJaAjKnBVmTtZcK0r0humsCMqwfTuF6doEMyNUiZEpCINI92IMaYypWx7QDjnl1I44Q6zJwwhBYN44MOydQwZT0DWiAiL4vIeWLdYoyp8jJ3e/f0qSXC89cMoW3ThKBDMjVQWRNQN+Ap4EogQ0T+JCLdoheWMSZatu/P5YpnFnAwN58ZVw+mU2KDoEMyNVSZEpB63lfVMcA1wHhgoYh8KiInRzVCY0yF2Xsoj3HPLmTrvlye+8VJ9GrbOOiQTA1W1mtALUTkFhFJA24HbgISgduAFyLUeVZEtonICl9ZfxH5UkSWiEiaiAz2TbtLRDJEZI2IDPeVDxKR5W7ak0VNgCISLyIvufIFIpJyLBvAmJri0JF8fjFtIRnb9vPUuEEM6miXdk2wytoENx9oDIxS1fNV9TVVzVfVNOCfEepMA0aElP0F+D9V7Q/c614jIr2A0UBvV2eyiBT1BZ0CTAS6ukfRMicAu1W1C/A48HAZ18WYGic3v4BrZy5iyaY9PDl6AKd3TQo6JGPKnIB+p6oPqGpmUYGIXAqgqmF3/Kr6GbArtBgvkQE0AbLd85HAbFXNVdV1QAYwWETaAI1Vdb6qKjADGOWrM909fwU4yzpIGHO0/IJCbp29hP9+s4OHfnYi5/ZtE3RIxgBlT0B3him76xje71bgERHZBPw/3zKSgU2++TJdWbJ7HlperI6q5gN7AbtVozE+hYXKXa8t590VW/j9T3txWWr7oEMy5nu1S5ooIucC5wHJIvKkb1JjIP8Y3m8S8CtVfVVELgOmAmcD4c5ctIRySplWjIhMxGvGo0OHDuWN2ZgqSVX549ureXlRJrec1ZUJp3UKOiRjiintDCgbSANygEW+xzxgeAn1IhkPvOaevwwUdULIBPyHZu3ce2e656HlxeqISG28Jr3QJj8AVPUpVU1V1dSkJGv7NjXDkx9m8Oz/1nHVKSncenbXoMMx5iglngGp6lJgqYjMcs1cxysbOAP4BDgT+MaVzwNeEJHHgLZ4nQ0WqmqBiOwXkaHAAmAc8DdfnfF4HSQuAT5y14mMqfGe+986Hv9gLT8b2I57f9rLbqtgYlJpTXBzVPUyIF1Ejtq5q+qJJdR9ERgGJIpIJnAf8Evgr+6MJQfXLKaqK0VkDrAKr2nvBlUtcIuahNejLgF41z3Aa76bKSIZeGc+o8uywsZUd68syuT/3lzF8N6tePhnfallt1UwMUpKOmkQkTaqullEOoabrqobohZZlKSmpmpaWlrQYRgTFe+t2ML1sxZxSudEpl6VSnxtG9naVAwRWaSqqRW5zNKa4Da7pw1UdVVIMMOAKpeAjKmuPv9mBze/mE6/9k3515WDLPmYmFfWbthzROS34kkQkb8Bf45mYMaYslu8cTcTZ6ZxQlIDpl01mAbxJR5bGhMTypqAhuD1OPsC+AqvM8Gp0QrKGFN2qzfv46pnF5LUKJ4ZEwbTpL7d08dUDWVNQHnAYbyOAPWAdapaGLWojDFlsn7HQa6cupD6dWvz/IQhtGxUL+iQjCmzsiagr/AS0EnAacAYEXklalEZY0q1ee9hxj6zgILCQp6/ZjDtm9cPOiRjyqWsDcUT3MCjAFuAkSJyZZRiMsaUYucB754+ew/n8eIvh9KlZaOgQzKm3Mp6BrRIRK4QkXsBRKQDsCZ6YRljItmfk8dVz31F5u7DTB2fSt92TYIOyZhjUtYENBk4GRjjXu8H/hGViEy1sXnvYQ4fKSh9RlNmOXkFTJiexurN+5hyxUCGnGDj75qqq6xNcENUdaCIpAOo6m4RqRvFuEwV98QHa3niA2+kpZaN4unYoj4dmjegY4v67nl9Ulo0oGn9OjZMTBkdyS9k0vOL+Gr9Lv46egBn9mgVdEjGHJeyJqA8d4M4BRCRJMB6wZmwPl6zjSc++IbhvVvRp20TNuw6xMadh/g8YzuvLs4tNm+jerW9pNS8AR1a1Kdj8/re3xYNaNO4ng0j4xQUKre9vJSP12znwYv6cGG/tkGHZMxxK2sCehKYC7QUkQfxBv/8XdSiMlVW1p7D/OqlJfRo3YgnLh9AQt3iv8Y/fKSATbsPsWHnITbsPMjGXYdYv/MQK7P38u+VW8gv/GFoqLpxtWjXPIGUFg3o0Ly+7+ypAe2bJ9SYX/qrKr9/YwVvLs3mtyN6MHZI2JGxjKlyypSAVHWWiCwCzsK7D88oVV0d1chMlXMkv5DrZy0mv0CZcsWgo5IPQELdOLq1akS3Vkf32sovKGTz3hwvOe06yMadLlHtOsSC73Zy0Hc9SQTaNK5HhxZeU14HdxbVsYV3BtW4XvX5MebD763hhQUbmTSsM5OGdQ46HGMqTGmjYTf3vdwGvOifpqph779jaqY/vbOapZv2MGXsQDolNih3/dpxtWjfvD7tm9fnNBKLTVNVdhw4wsZdB93Z0yE27vLOoj5YvZUdB44Um79Z/Tp0aNGAjs1915wSvddJjeKrzHWnyZ9k8M9Pv2XskA7cMbx70OEYU6FKOwNaRMl3Jj2hwiMyVdKbS7OZ9sV6JpzWiXP7tqnw5YsISY3iSWoUz6COzY+afiA3n407D7Fx10HWf5+gDrJ4427eWpaNr2WPhDpxdCi61lSUoFyySm6WQJ24snYOja7nv9zAX95bw4X92vLAyD5VJmkaU1aljYZt9/A1pcrYdoA7X13GoI7NuPPcHoHE0DC+Nr3aNqZX28ZHTTuSX0jWnsPfX3Mquv60fsdBPlu7ndz8H/rTxNUSkpsmfH/WFNp7r37dyhnk840lWfz+jRWc2aMlj17WzzpjmGqpzN8mEbkYbxgeBf6rqq9HKyhTdRw6ks/1sxYRXyeOv/98QMycPfjVrV2LTokNwjYLFhYq2/bnsmHnwe9763l/D/L28s3sOZRXbP7EhvGktKh/1DWnjs3r07xB3Qo5S/lw9VZum7OUwSnNmTx2YExuU2MqQpkSkIhMBrrwwzWg60TkHFW9IWqRmZinqtwzdwXfbDvAzKuH0KZJQtAhlVutWkLrJvVo3aRe2B917j2UxwZ33anomtOGnYeY/+1OXlucVWzehvG1fb313FmTa+pr0ySBuDKcxXz53U6un7WYnm0a88z4VOrVqRk9/UzNVNYzoDOAPupunyoi04HlUYvKVAkvLtzE3PQsfn1ON07rmlh6hSqoSf06nFi/KSe2a3rUtJy8AjJdl/L1O72zpg27DrFmy34+WL2VvIKQLuXNEny/dfKuOaUk1qdds/rUqxPHssw9XDM9jfbN6zP96sE0qkY9+YwJp6wJaA3QgR/ugNoeWBaViEyVsDxzL/fPW8mPuiVx44+7BB1OIOrViaNLy0ZhBwItKFQ27z38fZPe+p0/dCtPW7+bA7n5388rAq0b12N/Tj5N69fh+QlDaN7ABhox1V9ZE1ALYLWILHSvTwLmi8g8AFW9MBrBmdi091Aek2YtIrFhXZ64vL9dIA8jrpbQrpl3dnNKyDRVZdfBIz9cc3K/ezp8pIDfjuhB6yZ2Tx9TM5Q1Ad0b1ShMlVFYqPx6zhK27svhpWtPtiP1YyAitGgYT4uG8Qzs0CzocIwJTKnda9wYcL9X1U8jPSLUe1ZEtonIipDym0RkjYisFJG/+MrvEpEMN224r3yQiCx3054U181IROJF5CVXvkBEUo51I5iy+9dn3/Hh19u457yetvM0xhyXUhOQqhYAh0SkvDcdmQaM8BeIyI+BkcCJqtob+H+uvBcwGujt6kx2iQ9gCjAR6OoeRcucAOxW1S7A48DD5YzPlNP8b3fyyL+/5vwT2zD+lJSgwzHGVHFlbYLLAZaLyPvAwaJCVb05UgVV/SzMWckk4CFVzXXzbHPlI4HZrnydiGQAg0VkPdBYVecDiMgMYBTwrqtzv6v/CvB3EZGinnqmYm3bl8NNL6aTktiAh392ov0q3xhz3MqagN52j+PVDTjdjaidA9yuql8BycCXvvkyXVmeex5ajvu7CUBV80VkL15niR2hbyoiE/HOoujQoUMFrEbNkl9QyE0vpnMgN49Z1wyhYXzljAZgjKneyjoa9nQRSQA6qOrx3Iq7NtAMGIrXk26OiJxA5LHmIpVTyrTihapPAU8BpKam2hlSOT36/loWrNvFY5f1o3vro7scG2PMsSjTGB8icgGwBHjPve5f1AW7nDKB19SzEO+mdomuvL1vvnZAtitvF6Ycfx0RqQ00AWx07gr2waqtTPnkW8YM7sDFA9uVXsEYY8qorINM3Q8MBvYAqOoS4FgGKn0dOBNARLoBdfGazOYBo13Ptk54nQ0WqupmYL+IDHW938YBb7hlzQPGu+eXAB/Z9Z+KtWnXIX49Zwm92zbmvgt6BR2OMaaaKWtjfr6q7g258Fzizl5EXgSGAYkikgncBzwLPOu6Zh8BxruksVJE5gCrgHzgBtf7DryOC9OABLzOB++68qnATNdhYRdeLzpTQXLyCpg0axEAU8YOsjHJjDEVrqwJaIWI/ByIE5GuwM3AFyVVUNUxESZdEWH+B4EHw5SnAX3ClOcAl5YStzlGD7y1ihVZ+3h6XCodWtQPOhxjTDVU1ia4m/B+o5MLvADsBW6NUkwmYHPTM5m1YCPXndGZc3q1CjocY0w1VdotuesB1+HdimE5cLKq5pdUx1Rta7fu5+7XVjC4U3Nu/0m3oMMxxlRjpZ0BTQdS8ZLPubiRC0z1dCA3n+ueX0SD+Nr8fcwAatuN0IwxUVTaNaBeqtoXQESmAgtLmd9UUarKb19dxvodB5l1zVBaNrYRmY0x0VXaIe739yO2prfqbcb8Dby9bDO3D+/OyZ2PvjOoMcZUtNLOgPqJyD73XIAE91oAVdXGUY3OVIr0jbv549urOKtHS677UeegwzHG1BAlJiBVtR9/VHO7Dx7hhlmLadW4Ho9e1s9uLmeMqTQ2qmQNVlio3PrSEnYcOMIrk06maX27uZwxpvJYN6ca7B8fZ/Dp2u3ce0EvTmzXNOhwjDE1jCWgGurzb3bw2AdrGdW/LWOH2C0qjDGVzxJQDbRlbw63zE6nS1JDHryor91czhgTCEtANUxeQSE3vrCYw3kFTLliIA3s5nLGmIDY3qeG+ct7X5O2YTdPjhlAl5Z2czljTHDsDKgGeW/FZp7+7zrGn9yRC/u1DTocY0wNZwmohli34yC/eXkZ/do35e7zewYdjjHGWAKqCXLyCpj0/CLi4oR//HwA8bXt98XGmODZNaAa4N43VvD1lv0894uTaNfMbi5njIkNdgZUzc35ahNz0jK56cwu/Lh7y6DDMcaY71kCqsZWZe/j92+s4JTOLbj1bLu5nDEmtlgCqqb25eRx/axFNK1fhyfHDCDOBhk1xsQYuwZUDakqd7y8jE27DzN74lASG8YHHZIxxhwlamdAIvKsiGwTkRVhpt0uIioiib6yu0QkQ0TWiMhwX/kgEVnupj0pbtwYEYkXkZdc+QIRSYnWulQ1Uz9fx3srt3DniB6clNI86HCMMSasaDbBTQNGhBaKSHvgHGCjr6wXMBro7epMFpGivsJTgIlAV/coWuYEYLeqdgEeBx6OylpUMWnrd/HQu1/zk16tuOb0TkGHY4wxEUUtAanqZ8CuMJMeB+4A1Fc2Epitqrmqug7IAAaLSBugsarOV1UFZgCjfHWmu+evAGdJDR9Vc8eBXG58IZ3kZgk8cmk/G2TUGBPTKrUTgohcCGSp6tKQScnAJt/rTFeW7J6Hlhero6r5wF6gRYT3nSgiaSKStn379uNej1hUUKjcOnsJuw4dYfLYgTRJqBN0SMYYU6JKS0AiUh+4B7g33OQwZVpCeUl1ji5UfUpVU1U1NSkpqSzhVjl//fAbPs/YwQMje9O7bZOgwzHGmFJV5hlQZ6ATsFRE1gPtgMUi0hrvzKa9b952QLYrbxemHH8dEakNNCF8k1+198mabfzto2+4dFA7Lj/Jbi5njKkaKi0BqepyVW2pqimqmoKXQAaq6hZgHjDa9WzrhNfZYKGqbgb2i8hQd31nHPCGW+Q8YLx7fgnwkbtOVKNk7TnMrS8toXurRvxhZJ+gwzHGmDKLZjfsF4H5QHcRyRSRCZHmVdWVwBxgFfAecIOqFrjJk4Bn8DomfAu868qnAi1EJAP4NXBnVFYkhh3JL+T6WYvJL1CmXDGIhLo2yKgxpuqI2g9RVXVMKdNTQl4/CDwYZr404KhDe1XNAS49viirtj+9s5qlm/YwZexAOiU2CDocY4wpFxuKp4p6c2k2075Yz4TTOnFu3zZBh2OMMeVmCagKyth2gDtfXcagjs2489weQYdjjDHHxBJQFXPoSD7Xz1pEfJ04/v7zAdSJs3+hMaZqssFIqxBV5Z65K/hm2wFmXD2YNk0Sgg7JGGOOmR0+VyEvLtzE3PQsbj2rG6d3rZ4/qDXG1ByWgKqI5Zl7uX/eSn7ULYmbzuwSdDjGGHPcLAFVAXsP5XH9C4to0bAuT1zen1p2czljTDVg14BiXGGhctvLS9i8J4c5151M8wZ1gw7JGGMqhJ0Bxbh/ffYdH6zexj3n92Rgh2ZBh2OMMRXGElAMm//tTh7599ecf2IbrjolJehwjDGmQlkCilHb9uVw04vppCQ24OGfnWg3lzPGVDt2DSgG5RcUctOL6RzIzWPWNUNoGG//JmNM9WN7thj06PtrWbBuF49d1o/urRsFHY4xxkSFNcHFmA9WbWXKJ98yZnAHLh7YrvQKxhhTRVkCiiGbdh3i13OW0LttY+67oFfQ4RhjTFRZAooROXkFTJq1CAWmjB1EvTp2czljTPVm14BixANvrWJF1j6eHpdKhxb1gw7HGGOizs6AYsDc9ExmLdjItWecwDm9WgUdjjHGVApLQAFbu3U/d7+2gsGdmvObn3QPOhxjjKk0loACdCA3n+ueX0SD+Nr8fcwAatvN5YwxNYjt8QKiqtz56jLW7zjIk2P607JxvaBDMsaYShW1BCQiz4rINhFZ4St7RES+FpFlIjJXRJr6pt0lIhkiskZEhvvKB4nIcjftSXFj0ohIvIi85MoXiEhKtNYlGmbM38BbyzZz20+6c0rnxKDDMcaYShfNM6BpwIiQsveBPqp6IrAWuAtARHoBo4Hers5kESnqhzwFmAh0dY+iZU4AdqtqF+Bx4OGorUkFS9+4mz++vYqzerRk0hmdgw7HGGMCEbUEpKqfAbtCyv6jqvnu5ZdA0U/9RwKzVTVXVdcBGcBgEWkDNFbV+aqqwAxglK/OdPf8FeAsqQIjdu4+eIQbZi2mVeN6PHpZP7u5nDGmxgryGtDVwLvueTKwyTct05Ulu+eh5cXquKS2F2gR7o1EZKKIpIlI2vbt2ytsBcqrsFC59aUl7DhwhMljB9K0vt1czhhTcwWSgETkHiAfmFVUFGY2LaG8pDpHF6o+paqpqpqalJRU3nArzD8+zuDTtdu594JenNiuaWBxGGNMLKj0BCQi44GfAmNdsxp4ZzbtfbO1A7Jdebsw5cXqiEhtoAkhTX6x5PNvdvDYB2sZ1b8tY4d0CDocY4wJXKUmIBEZAfwWuFBVD/kmzQNGu55tnfA6GyxU1c3AfhEZ6q7vjAPe8NUZ755fAnzkS2gxZcveHG6ZnU6XpIY8eFFfu7mcMcYQxbHgRORFYBiQKCKZwH14vd7igffdTvhLVb1OVVeKyBxgFV7T3A2qWuAWNQmvR10C3jWjoutGU4GZIpKBd+YzOlrrcjzyCgq58YXFHM4rYMoVA2lgN5czxhgAJEZPGqImNTVV09LSKu39Hnx7FU//dx1PjhnAhf3aVtr7GmNMRRKRRaqaWpHLtJEQoui9FZt5+r/rGHdyR0s+xhgTwhJQlKzfcZDfvLyMfu2acM/5PYMOxxhjYo4loCjwbi63mFq1hH+MHUh8bbu5nDHGhLIr4lFw7xsrWL15H89ddRLtmtnN5YwxJhw7A6pgc77axJy0TG78cRd+3KNl0OEYY0zMsgRUgVZl7+P3b6zglM4t+NU53YIOxxhjYpoloAqyLyeP62ctomn9Ojw5ZgBxNsioMcaUyK4BVQBV5Y6Xl7Fp92FmTxxKYsP4oEMyxpiYZ2dAFWDq5+t4b+UW7hzRg5NSmgcdjjHGVAmWgI5T2vpdPPTu1/ykVyuuOb1T0OEYY0yVYQnoOOw4kMuNL6ST3CyBRy7tZ4OMGmNMOdg1oGNUUKjcOnsJuw4dYe71p9AkoU7QIRljTJViZ0DH6K8ffsPnGTt4YGRverdtEnQ4xhhT5VgCOgafrNnG3z76hksGteOy1PalVzDGGHMUS0DllLXnMLe+tITurRrxwMg+dt3HGGOOkSWgcjiSX8j1sxaTX6BMHjuQhLo2yKgxxhwr64RQDn96ZzVLN+1h8tiBnJDUMOhwjDGmSrMzoDJ6c2k2075Yz9WnduK8vm2CDscYY6o8S0Bl1LxBXc7p1Yq7zusRdCjGGFMtWBNcGZ3aJZFTuyQGHYYxxlQbUTsDEpFnRWSbiKzwlTUXkfdF5Bv3t5lv2l0ikiEia0RkuK98kIgsd9OeFNftTETiReQlV75ARFKitS7GGGMqXjSb4KYBI0LK7gQ+VNWuwIfuNSLSCxgN9HZ1JotIURezKcBEoKt7FC1zArBbVbsAjwMPR21NjDHGVLioJSBV/QzYFVI8Epjunk8HRvnKZ6tqrqquAzKAwSLSBmisqvNVVYEZIXWKlvUKcJbYj3KMMabKqOxOCK1UdTOA+1t0z+pkYJNvvkxXluyeh5YXq6Oq+cBeoEW4NxWRiSKSJiJp27dvr6BVMcYYczxipRdcuDMXLaG8pDpHF6o+paqpqpqalJR0jCEaY4ypSJWdgLa6ZjXc322uPBPwD6rWDsh25e3ClBerIyK1gSYc3eRnjDEmRlV2ApoHjHfPxwNv+MpHu55tnfA6Gyx0zXT7RWSou74zLqRO0bIuAT5y14mMMcZUAVH7HZCIvAgMAxJFJBO4D3gImCMiE4CNwKUAqrpSROYAq4B84AZVLXCLmoTXoy4BeNc9AKYCM0UkA+/MZ3S01sUYY0zFk5p20iAi24ENx1g9EdhRgeFUFIurfCyu8ovV2Cyu8jmeuDqqaoVeRK9xCeh4iEiaqqYGHUcoi6t8LK7yi9XYLK7yibW4YqUXnDHGmBrGEpAxxphAWAIqn6eCDiACi6t8LK7yi9XYLK7yiam47BqQMcaYQNgZkDHGmEBYAjLGGBMIS0ARlPd+RgHHdb+IZInIEvc4L4C42ovIxyKyWkRWisgtrjzQbVZCXIFuMxGpJyILRWSpi+v/XHnQ2ytSXIF/xlwccSKSLiJvudeBfycjxBX49hKR9e5eaktEJM2VxcT2KmIJKLJplPF+RpVsGkfHBfC4qvZ3j3cqOSbwRrC4TVV7AkOBG9x9noLeZpHigmC3WS5wpqr2A/oDI0RkKMFvr0hxQfCfMYBbgNW+10FvryKhcUFsbK8fu/cv+u1PrGwvwBJQROW8n1GliRBX4FR1s6ouds/3430Zkwl4m5UQV6DUc8C9rOMeSvDbK1JcgRORdsD5wDO+4sC/kxHiilWBby8/S0DlE+l+RrHgRhFZ5proAj2tdrdHHwAsIIa2WUhcEPA2c802S/BGhX9fVWNie0WIC4L/jD0B3AEU+soC314R4oLgt5cC/xGRRSIy0ZXFwvb6niWg6mEK0BmvyWQz8GhQgYhIQ+BV4FZV3RdUHKHCxBX4NlPVAlXtj3ebkcEi0qeyYwgnQlyBbi8R+SmwTVUXVeb7lqaEuAL/fAGnqupA4Fy8pucfBRBDiSwBlU+k+xkFSlW3up1GIfA0MDiIOESkDt5OfpaqvuaKA99m4eKKlW3mYtkDfIJ3bS/w7RUurhjYXqcCF4rIemA2cKaIPE/w2ytsXDGwvVDVbPd3GzDXxRD09irGElD5RLqfUaCKPlDORcCKSPNGMQbBu0XGalV9zDcp0G0WKa6gt5mIJIlIU/c8ATgb+Jrgt1fYuILeXqp6l6q2U9UUvFuvfKSqVxDw9ooUV9DbS0QaiEijoufAT1wMMbUPi9r9gKo6Kcf9jGIgrmEi0h+vzXc9cG1lx4V3JHglsNxdPwC4m+C3WaS4xgS8zdoA00UkDu9AcI6qviUi8wl2e0WKa2YMfMbCCfrzFclfAt5erYC53vEXtYEXVPU9EfmKGNpeNhSPMcaYQFgTnDHGmEBYAjLGGBMIS0DGGGMCYQnIGGNMICwBGWOMCYQlIFMjiIiKyKO+17eLyP0VtOxpInJJRSyrlPe5VLxRvT8OKU8RkZ8f57K/OL7ojCk/S0CmpsgFLhaRxKAD8XO/tymrCcD1qvrjkPIU4LgSkKqecjz1jTkWloBMTZEPPAX8KnRC6BmMiBxwf4eJyKciMkdE1orIQyIyVrz75SwXkc6+xZwtIv918/3U1Y8TkUdE5Cs3KOW1vuV+LCIvAMvDxDPGLX+FiDzsyu4FTgP+KSKPhFR5CDhdvPu+/Eq8e/o855aRLiI/dsu4SkTeEJH3RGSNiNwXus7u+R2u7lIReciV3Swiq9x6zC7PhjcmEhsJwdQk/wCWichfylGnH9AT7xYY3wHPqOpg8W5sdxNwq5svBTgDbwDKj0WkCzAO2KuqJ4lIPPA/EfmPm38w0EdV1/nfTETaAg8Dg4DdeKMZj1LVP4jImcDtqpoWEuOdrrwo8d0GoKp9RaSHW0Y3//sCh4CvRORt//JE5Fy8IfqHqOohEWnue49OqppbNFSPMcfLzoBMjeFGwZ4B3FyOal+5ewrlAt8CRQlkOV7SKTJHVQtV9Ru8RNUDb/ytcW4IoAVAC6Crm39haPJxTgI+UdXtqpoPzALKO4rxacBMAFX9GtgAFCWg91V1p6oeBl5z8/qdDTynqodc/aJ7Ty0DZonIFXhnk8YcN0tApqZ5Au9aSgNfWT7uu+AGL63rm5bre17oe11I8RaE0DGtFBDgJt9dMTupalECOxghPinjepSkpGWEizO0brjxuc7HO4McBCwSEWs9McfNEpCpUdwR/Ry8JFRkPd6OFbw7RtY5hkVfKiK13HWhE4A1wL+BSeLdDgIR6eZGJi7JAuAMEUl0HRTGAJ+WUmc/0Mj3+jNgbNF7Ah1cPADniEhzN9L1KOB/Icv6D3C1iNR39ZuLSC2gvap+jHfjtaZAw1JiMqZUdhRjaqJHgRt9r58G3hCRhcCHRD47KckavETRCrhOVXNE5Bm8ZrrF7sxqO6XcAllVN4vIXcDHeGcj76hqaUPmLwPyRWQpMA2YjNdZYTne2d1V7toNwOd4zXNd8EZILnY9yY2Y3B9IE5EjwDt4I64/LyJNXEyPu3sFGXNcbDRsY2oIEbkKSFXVG0ub15jKYE1wxhhjAmFnQMYYYwJhZ0DGGGMCYQnIGGNMICwBGWOMCYQlIGOMMYGwBGSMMSYQ/x9X1NpGFq0F3wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\r\n",
    "\r\n",
    "def lda_perplexity(vectorizer, data_train, data_test):\r\n",
    "\r\n",
    "    ''' Showing the perplexity score for several LDA models with different values\r\n",
    "    for n_components parameter, and printing the top words for the best LDA model\r\n",
    "    (the one with the lowest perplexity)\r\n",
    "    Parameters:\r\n",
    "    vectorizer: TF-IDF convertizer                                              \r\n",
    "    data_train: data to fit the model with\r\n",
    "    data_test: data to test\r\n",
    "    '''\r\n",
    "\r\n",
    "    best_perplexity = np.inf\r\n",
    "    best_lda = 0\r\n",
    "    perplexity_list = []\r\n",
    "    n_topics_list = []\r\n",
    "    print(\"Extracting term frequency features for LDA...\")\r\n",
    "\r\n",
    "    for n_topics in np.linspace(10, 50, 5, dtype='int'):\r\n",
    "        lda_model = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\r\n",
    "                                        learning_method='online',\r\n",
    "                                        learning_offset=50.,\r\n",
    "                                        random_state=0).fit(data_train)\r\n",
    "        n_topics_list.append(n_topics)\r\n",
    "        perplexity = lda_model.perplexity(data_test)\r\n",
    "        perplexity_list.append(perplexity)\r\n",
    "\r\n",
    "        # Perplexity is defined as exp(-1. * log-likelihood per word)\r\n",
    "        # Perplexity: The smaller the better\r\n",
    "        if perplexity <= best_perplexity:\r\n",
    "            best_perplexity = perplexity\r\n",
    "            best_lda = lda_model\r\n",
    "                                \r\n",
    "    plt.title(\"Evolution of perplexity score depending on number of topics\")\r\n",
    "    plt.xlabel(\"Number of topics\")\r\n",
    "    plt.ylabel(\"Perplexity\")\r\n",
    "    plt.plot(n_topics_list, perplexity_list)\r\n",
    "    plt.savefig('img/complexity.png', bbox_inches='tight')\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "lda_perplexity(vectorizer_tfidf, X_tfidf_train, X_tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest perplexity score is for 10 topics, so we will learn the lda model with 10 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 10\r\n",
    "\r\n",
    "lda_model_tfidf = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\r\n",
    "                                    learning_method='online',\r\n",
    "                                    learning_offset=50.,\r\n",
    "                                    random_state=0).fit(X_tfidf_train)\r\n",
    "\r\n",
    "feature_names = vectorizer_tfidf.get_feature_names()\r\n",
    "lda_components = lda_model_tfidf.components_ / lda_model_tfidf.components_.sum(axis=1)[:, np.newaxis] # normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainons également un modèle qui se base sur un Countvectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "vectorizer_tf = CountVectorizer(max_features=10000)\r\n",
    "X_tf_train = vectorizer_tf.fit_transform(X_lda_train)\r\n",
    "\r\n",
    "n_topics = 10\r\n",
    "\r\n",
    "lda_model_tf = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\r\n",
    "                                    learning_method='online',\r\n",
    "                                    learning_offset=50.,\r\n",
    "                                    random_state=0).fit(X_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tag(text_test, vectorizer, model):\r\n",
    "\r\n",
    "    text_tfidf = vectorizer.transform(text_test)\r\n",
    "    text_projection = model.transform(text_tfidf)\r\n",
    "\r\n",
    "    threshold = 0.005 # defined after tests\r\n",
    "    list_scores = []\r\n",
    "    list_words = []\r\n",
    "    used = set()\r\n",
    "\r\n",
    "    lda_components = model.components_ / model.components_.sum(axis=1)[:, np.newaxis] # normalization\r\n",
    "    feature_names = vectorizer.get_feature_names()\r\n",
    "\r\n",
    "    for topic in range(n_topics):\r\n",
    "        topic_score = text_projection[0][topic]\r\n",
    "\r\n",
    "        for (word_idx, word_score) in zip(lda_components[topic].argsort()[:-5:-1], sorted(lda_components[topic])[:-5:-1]):\r\n",
    "            score = topic_score*word_score\r\n",
    "\r\n",
    "            if score >= threshold:\r\n",
    "                list_scores.append(score)\r\n",
    "                list_words.append(feature_names[word_idx])\r\n",
    "                used.add(feature_names[word_idx])\r\n",
    "\r\n",
    "    results = [tag for (y,tag) in sorted(zip(list_scores,list_words), key=lambda pair: pair[0], reverse=True)]\r\n",
    "    tags = \" \".join(results[:5])\r\n",
    "\r\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string array value list'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'string value return object table'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'php array string'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\r\n",
    "text_test = [X_lda_test[0]]\r\n",
    "\r\n",
    "return_tag(text_test, vectorizer_tfidf, lda_model_tfidf)\r\n",
    "return_tag(text_test, vectorizer_tf, lda_model_tf)\r\n",
    "y_lda_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'évaluation du modèle nous allons prédire les tags et les comparer visuellement aux valeurs réelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tf = X_lda_test.apply(lambda x: return_tag([x], vectorizer_tf, lda_model_tf))\r\n",
    "y_pred_tfidf = X_lda_test.apply(lambda x: return_tag([x], vectorizer_tfidf, lda_model_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred_tf</th>\n",
       "      <th>y_pred_tfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreationDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-09-20 19:13:46</th>\n",
       "      <td>array string php best method converting php ar...</td>\n",
       "      <td>string value return object table</td>\n",
       "      <td>string array value list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-20 01:51:21</th>\n",
       "      <td>bootstrap collapse show state icon using core ...</td>\n",
       "      <td>div function text html</td>\n",
       "      <td>div git image cs color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-02 16:46:10</th>\n",
       "      <td>prevent autocomplete visual studio code using ...</td>\n",
       "      <td>file window use would system</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-15 14:04:43</th>\n",
       "      <td>determine cpu memory inside process task deter...</td>\n",
       "      <td>use would one code file</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-07 14:37:42</th>\n",
       "      <td>multiple downloads using wget using wget downl...</td>\n",
       "      <td>file line way like http</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-16 05:09:50</th>\n",
       "      <td>understanding garbage collection .net consider...</td>\n",
       "      <td>string value return object</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-27 08:19:27</th>\n",
       "      <td>difference use getapplicationcontext someclass...</td>\n",
       "      <td>android java layout org string</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-05 20:55:03</th>\n",
       "      <td>import existing git repository another git rep...</td>\n",
       "      <td>git file date branch repository</td>\n",
       "      <td>git branch commit repository</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-07 11:02:47</th>\n",
       "      <td>jump method go back previous method making jum...</td>\n",
       "      <td>file line way like window</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-04 16:08:15</th>\n",
       "      <td>automatically update timestamp postgresql want...</td>\n",
       "      <td>table id name data file</td>\n",
       "      <td>date string array datetime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                y_true  \\\n",
       "CreationDate                                                             \n",
       "2011-09-20 19:13:46  array string php best method converting php ar...   \n",
       "2013-08-20 01:51:21  bootstrap collapse show state icon using core ...   \n",
       "2015-10-02 16:46:10  prevent autocomplete visual studio code using ...   \n",
       "2008-09-15 14:04:43  determine cpu memory inside process task deter...   \n",
       "2010-08-07 14:37:42  multiple downloads using wget using wget downl...   \n",
       "2013-06-16 05:09:50  understanding garbage collection .net consider...   \n",
       "2012-04-27 08:19:27  difference use getapplicationcontext someclass...   \n",
       "2009-11-05 20:55:03  import existing git repository another git rep...   \n",
       "2011-10-07 11:02:47  jump method go back previous method making jum...   \n",
       "2012-03-04 16:08:15  automatically update timestamp postgresql want...   \n",
       "\n",
       "                                            y_pred_tf  \\\n",
       "CreationDate                                            \n",
       "2011-09-20 19:13:46  string value return object table   \n",
       "2013-08-20 01:51:21            div function text html   \n",
       "2015-10-02 16:46:10      file window use would system   \n",
       "2008-09-15 14:04:43           use would one code file   \n",
       "2010-08-07 14:37:42           file line way like http   \n",
       "2013-06-16 05:09:50        string value return object   \n",
       "2012-04-27 08:19:27    android java layout org string   \n",
       "2009-11-05 20:55:03   git file date branch repository   \n",
       "2011-10-07 11:02:47         file line way like window   \n",
       "2012-03-04 16:08:15           table id name data file   \n",
       "\n",
       "                                     y_pred_tfidf  \n",
       "CreationDate                                       \n",
       "2011-09-20 19:13:46       string array value list  \n",
       "2013-08-20 01:51:21        div git image cs color  \n",
       "2015-10-02 16:46:10                          file  \n",
       "2008-09-15 14:04:43                          file  \n",
       "2010-08-07 14:37:42                                \n",
       "2013-06-16 05:09:50                          file  \n",
       "2012-04-27 08:19:27                          file  \n",
       "2009-11-05 20:55:03  git branch commit repository  \n",
       "2011-10-07 11:02:47                          file  \n",
       "2012-03-04 16:08:15    date string array datetime  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame({'y_true' : X_lda_test, 'y_pred_tf' : y_pred_tf, 'y_pred_tfidf' : y_pred_tfidf})\r\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons que l'approche non supervisée donne systématiquement des tags différents de ceux réels.  \r\n",
    "Pour aller plus loin nous pourrions utiliser fastLDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\r\n",
    "## 3.2 NMF\r\n",
    "\r\n",
    "Une autre type de modélisation de sujet automatique non supervisée est NMF (Negative Matrix Factorisation).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, init='nndsvd', l1_ratio=0.5, n_components=20, random_state=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\r\n",
    "\r\n",
    "# NMF is able to use tf-idf\r\n",
    "tfidf_vectorizer = TfidfVectorizer(\r\n",
    "    max_features=10000,\r\n",
    "    analyzer=lambda x: x, # disable the analyser as we already have tokens\r\n",
    "    stop_words='english')\r\n",
    "tfidf = tfidf_vectorizer.fit_transform(df.Text_tok)\r\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\r\n",
    "\r\n",
    "no_topics = 20\r\n",
    "\r\n",
    "# Run NMF\r\n",
    "nmf = NMF(n_components=no_topics,\r\n",
    "random_state=1,\r\n",
    "alpha=.1,\r\n",
    "l1_ratio=.5,\r\n",
    "init='nndsvd') # Nonnegative Double Singular Value Decomposition (NNDSVD) initialization (better for sparseness)\r\n",
    "\r\n",
    "nmf.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\r\n",
    "    for topic_idx, topic in enumerate(model.components_):\r\n",
    "        print(\"Topic {}:\".format(topic_idx))\r\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\r\n",
    "\r\n",
    "no_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "use would user error using code get like http application\n",
      "Topic 1:\n",
      "file directory folder path txt open filename name read want\n",
      "Topic 2:\n",
      "android layout id app activity view studio com parent width\n",
      "Topic 3:\n",
      "string character convert str split replace number way char hello\n",
      "Topic 4:\n",
      "git branch commit repository remote master push change github origin\n",
      "Topic 5:\n",
      "div px cs element text image width height html id\n",
      "Topic 6:\n",
      "table column sql mysql database row query data select id\n",
      "Topic 7:\n",
      "array element numpy arr var way javascript index php int\n",
      "Topic 8:\n",
      "class public method static int void test private foo name\n",
      "Topic 9:\n",
      "line command script bash text run window output vim echo\n",
      "Topic 10:\n",
      "list item element arraylist way index sort new would like\n",
      "Topic 11:\n",
      "function javascript return var jquery call script event alert php\n",
      "Topic 12:\n",
      "difference v use two one explain used ruby example understand\n",
      "Topic 13:\n",
      "date format time datetime day mm month current convert dd\n",
      "Topic 14:\n",
      "python py install package module print import pip self version\n",
      "Topic 15:\n",
      "object json javascript property var data name obj id type\n",
      "Topic 16:\n",
      "value key input type option name dictionary variable form field\n",
      "Topic 17:\n",
      "c int std char objective program pointer code compiler include\n",
      "Topic 18:\n",
      "java org lang jdk eclipse maven util apache integer jar\n",
      "Topic 19:\n",
      "node j module npm install script err error app require\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\r\n",
    "# 4. Approche supervisée\r\n",
    "<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Sommaire</a>\r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "<a id=\"4.1\"></a>\r\n",
    "## 4.1 Doc2vec\r\n",
    "\r\n",
    "Doc2vec est un algorithme supervisé de plongement de mots.\r\n",
    "Les algorithmes utilisés dans l'architecture de doc2vec sont “distributed memory” (dm) et “distributed bag of words” (dbow).\r\n",
    "\r\n",
    "Pour ce plongement de mots il est nécessaire d'associer les tags au corpus.  \r\n",
    "Nous séparerons tout d'abord notre jeu de donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"Text_tok\"], df['Tags_tok'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to put our data in a specific form for doc2vec\r\n",
    "train_corpus = [models.doc2vec.TaggedDocument(doc, i) for doc, i in zip(x_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = x_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancing the model\r\n",
    "model_d2v = models.doc2vec.Doc2Vec(vector_size=50,\r\n",
    "min_count=2,\r\n",
    "epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d2v.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'android' appeared 8627 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "# sample\r\n",
    "print(f\"Word 'android' appeared {model_d2v.wv.get_vecattr('android', 'count')} times in the training corpus.\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d2v.train(train_corpus, total_examples=model_d2v.corpus_count, epochs=model_d2v.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'évaluation nous utiliserons le metric Jaccrd score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\r\n",
    "\r\n",
    "# I expect to see RuntimeWarnings in this block\r\n",
    "with warnings.catch_warnings():\r\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\r\n",
    "\r\n",
    "    scores = []\r\n",
    "\r\n",
    "    for i in range(0, len(y_test)-1):\r\n",
    "        inferred_vector = model_d2v.infer_vector(test_corpus[i])\r\n",
    "        sims = model_d2v.dv.most_similar([inferred_vector], topn=len(set(y_test[i])))\r\n",
    "        # [w[0] for w in sims]\r\n",
    "        # y_test[i]\r\n",
    "\r\n",
    "        y_pred = sorted(set([w[0] for w in sims]))    \r\n",
    "        y_true = sorted(set(y_test[i]))\r\n",
    "        \r\n",
    "        scores.append(metrics.jaccard_score(y_true, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.169109760457633"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean\r\n",
    "\r\n",
    "mean([s for s in scores if str(s) != 'nan'])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.2\"></a>\r\n",
    "## 4.2 SGD, Logistic regression, LinearSVC\r\n",
    "\r\n",
    "Nous allons maintenant entrainer les modèles SGD, Logistic regression, LinearSVC avec le classifieur One versus Rest.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-655508f5bf7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tags_tok'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['Tags_tok'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel = MultiLabelBinarizer()\r\n",
    "y = multilabel.fit_transform(df['Tags_tok'])\r\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.net</th>\n",
       "      <th>4net</th>\n",
       "      <th>aapt</th>\n",
       "      <th>aar</th>\n",
       "      <th>abort</th>\n",
       "      <th>absolute</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>access</th>\n",
       "      <th>accessor</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yum</th>\n",
       "      <th>zend</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zsh</th>\n",
       "      <th>zurb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28072</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28073</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28074</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28075</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28076</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28077 rows × 2834 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       .net  4net  aapt  aar  abort  absolute  abstract  abstraction  access  \\\n",
       "0         1     0     0    0      0         0         0            0       0   \n",
       "1         0     0     0    0      0         0         0            0       0   \n",
       "2         0     0     0    0      0         0         0            0       0   \n",
       "3         0     0     0    0      0         0         0            0       0   \n",
       "4         0     0     0    0      0         0         0            0       0   \n",
       "...     ...   ...   ...  ...    ...       ...       ...          ...     ...   \n",
       "28072     0     0     0    0      0         0         0            0       0   \n",
       "28073     0     0     0    0      0         0         0            0       0   \n",
       "28074     0     0     0    0      0         0         0            0       0   \n",
       "28075     0     0     0    0      0         0         0            0       0   \n",
       "28076     0     0     0    0      0         0         0            0       0   \n",
       "\n",
       "       accessor  ...  year  yield  youtube  yum  zend  zero  zip  zoom  zsh  \\\n",
       "0             0  ...     0      0        0    0     0     0    0     0    0   \n",
       "1             0  ...     0      0        0    0     0     0    0     0    0   \n",
       "2             0  ...     0      0        0    0     0     0    0     0    0   \n",
       "3             0  ...     0      0        0    0     0     0    0     0    0   \n",
       "4             0  ...     0      0        0    0     0     0    0     0    0   \n",
       "...         ...  ...   ...    ...      ...  ...   ...   ...  ...   ...  ...   \n",
       "28072         0  ...     0      0        0    0     0     0    0     0    0   \n",
       "28073         0  ...     0      0        0    0     0     0    0     0    0   \n",
       "28074         0  ...     0      0        0    0     0     0    0     0    0   \n",
       "28075         0  ...     0      0        0    0     0     0    0     0    0   \n",
       "28076         0  ...     0      0        0    0     0     0    0     0    0   \n",
       "\n",
       "       zurb  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "28072     0  \n",
       "28073     0  \n",
       "28074     0  \n",
       "28075     0  \n",
       "28076     0  \n",
       "\n",
       "[28077 rows x 2834 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf = pd.DataFrame(y, columns=multilabel.classes_)\r\n",
    "ydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tfidf = TfidfVectorizer(\r\n",
    "    analyzer='word',\r\n",
    "    max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28077, 5261), (28077, 2834))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vec_tfidf.fit_transform(df['Text'].values)\r\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\r\n",
    "lr = LogisticRegression(solver='lbfgs')\r\n",
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les problèmes de **classification multi-label** doivent être évalués à l'aide de mesures de performance différentes des problèmes de classification mono-étiquette.  \r\n",
    "Deux des mesures de performance les plus courantes sont \"hamming loss\" et la \"Jaccard similarity\". Nous utiliserons ici cette dernière.\r\n",
    "\r\n",
    "**Jaccard similarity** : la taille de l'intersection des étiquettes prédites et des étiquettes vraies divisée par la taille de l'union des étiquettes prédites et vraies.  \r\n",
    "Il va de 0 à 1, et 1 est le score parfait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_score(y_true, y_pred):\r\n",
    "  jaccard = np.minimum(y_true, y_pred).sum(axis = 1)/np.maximum(y_true, y_pred).sum(axis = 1)\r\n",
    "  return jaccard.mean()*100\r\n",
    "\r\n",
    "\r\n",
    "def print_score(y_pred, y_test, clf):\r\n",
    "  print(\"Clf: \", clf.__class__.__name__)\r\n",
    "  print('Jaccard score: {}'.format(j_score(y_test, y_pred)))\r\n",
    "  print('----')\r\n",
    "\r\n",
    "def get_best_tags(clf, X, lb, n_tags=3):\r\n",
    "  decfun = clf.decision_function(X)\r\n",
    "  best_tags = np.argsort(decfun)[:, :-(n_tags+1): -1]\r\n",
    "  return lb.classes_[best_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier())"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  SGDClassifier\n",
      "Jaccard score: 22.121874524652306\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  LogisticRegression\n",
      "Jaccard score: 16.706728456728456\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC())"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  LinearSVC\n",
      "Jaccard score: 29.641941905830794\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import warnings\r\n",
    "\r\n",
    "# I expect to see RuntimeWarnings in this block\r\n",
    "with warnings.catch_warnings():\r\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\r\n",
    "\r\n",
    "    for classifier in [sgd, lr, svc]:\r\n",
    "      clf = OneVsRestClassifier(classifier)\r\n",
    "      clf.fit(X_train, y_train) \r\n",
    "      # y_pred = clf.predict(X_test)\r\n",
    "      best_tags = get_best_tags(clf, X_test, multilabel)\r\n",
    "      y_pred = multilabel.transform(best_tags)\r\n",
    "      print_score(y_pred, y_test, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous choisirons un modèle LinearSVC pour estimer les tags d'une nouvelle question.  \r\n",
    "Tentons d'améliorer le score de Jaccard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.5, dual=False, penalty='l1'))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  LinearSVC\n",
      "Jaccard score: 32.506987354209585\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(C=1.5, penalty='l1', dual=False)\r\n",
    "\r\n",
    "with warnings.catch_warnings():\r\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\r\n",
    "\r\n",
    "    for classifier in [svc]:\r\n",
    "      clf_svc = OneVsRestClassifier(classifier)\r\n",
    "      clf_svc.fit(X_train, y_train) \r\n",
    "      best_tags = get_best_tags(clf_svc, X_test, multilabel)\r\n",
    "      y_pred = multilabel.transform(best_tags)\r\n",
    "      print_score(y_pred, y_test, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle ayant la meilleur performance ce sera celui ci que nous utiliserons pour la prédiction de nos tags via API.\r\n",
    "\r\n",
    "Nous pourrions également tenter de jouer sur les paramètres  de tfidf, par exemple ngram_range=(1, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['file', 'python', 'renaming']], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\r\n",
    "x = [ 'how to write ml code in python and java i have data but do not know how to do it']\r\n",
    "xt = vec_tfidf.transform(x)\r\n",
    "get_best_tags(clf_svc, xt, multilabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\r\n",
    "# 5. Installation du modèle sur API\r\n",
    "<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Sommaire</a>\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "Pour le déploiement du modèle sur une API nous devrons le sauvegarder en fichier pour que le serveur puisse s'en servir.  \r\n",
    "De plus le process de prédiction devra être mis en forme pour s'adapter à Flask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.1\"></a>\r\n",
    "## 5.1 Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_svc.pkl']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['multilabel.pkl']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['vec_tfidf.pkl']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_svc, \"clf_svc.pkl\", compress=3)\r\n",
    "joblib.dump(multilabel, \"multilabel.pkl\")\r\n",
    "joblib.dump(vec_tfidf, \"vec_tfidf.pkl\") # joblib doesn't want to put this one in models repertory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.2\"></a>\r\n",
    "## 5.2 Mise en forme process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\r\n",
    "\r\n",
    "def import_model():\r\n",
    "    model = joblib.load(\"clf_svc.pkl\")\r\n",
    "    sw = joblib.load(\"sw.pkl\")\r\n",
    "    lb = joblib.load(\"multilabel.pkl\")\r\n",
    "    vec = joblib.load(\"vec_tfidf.pkl\")\r\n",
    "    return (model, sw, lb, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "model, sw, lb, vec = import_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import re\r\n",
    "import nltk\r\n",
    "# nltk.download('punkt')\r\n",
    "# nltk.download('stopwords')\r\n",
    "# nltk.download('wordnet')\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import contractions\r\n",
    "\r\n",
    "def cleaner(text):\r\n",
    "    \"\"\"Remove Html tags, extra spaces, ; put in lowercase\"\"\"\r\n",
    "\r\n",
    "    text = BeautifulSoup(text, 'html.parser')\r\n",
    "    text = text.get_text(strip=True)\r\n",
    "    text = contractions.fix(text) # remove contractions 's => is...\r\n",
    "    text = re.sub(r\"\\n\", \" \", text) # match all literal Line Feed (New line) pattern then replace them by a single whitespace\r\n",
    "    text = re.sub(r'\\s+', ' ', text) # match all one or more whitespace then replace them by a single whitespace\r\n",
    "    text = text.lower()\r\n",
    "\r\n",
    "    return text\r\n",
    "\r\n",
    "def tokeniser(text):\r\n",
    "    return nltk.RegexpTokenizer(r'[a-zA-Z]{2,}|c#?|.net').tokenize(text)\r\n",
    "\r\n",
    "def remove_stopwords(list_of_words, sw):\r\n",
    "    \"\"\"remove common words in english by using nltk.corpus's list\"\"\"\r\n",
    "\r\n",
    "    list_of_words = [w for w in list_of_words if not w in sw]\r\n",
    "    return list_of_words\r\n",
    "\r\n",
    "\r\n",
    "def lem_text(list_of_words):\r\n",
    "    \"\"\"Lemmatization of the text\"\"\"\r\n",
    "\r\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\r\n",
    "    list_of_words = [lemmatizer.lemmatize(w) for w in list_of_words] # Lemmatize each words\r\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_treatment(input_txt, sw):\r\n",
    "   txt = cleaner(input_txt)\r\n",
    "   txt = tokeniser(txt)\r\n",
    "   txt = remove_stopwords(txt, sw)\r\n",
    "   txt = lem_text(txt)\r\n",
    "   # vectorizer needs a  list of strings\r\n",
    "   # it then tokenise it\r\n",
    "   txt = [' '.join(txt)] \r\n",
    "   return txt\r\n",
    "\r\n",
    "def vectorize(x, vec):\r\n",
    "   return vec.transform(x)\r\n",
    "\r\n",
    "def get_best_tags(clf, X, lb, n_tags=3):\r\n",
    "    decfun = clf.decision_function(X)\r\n",
    "    best_tags = np.argsort(decfun)[:, :-(n_tags+1): -1]\r\n",
    "    return lb.classes_[best_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['python', 'java', 'env']], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def treat_text_get_tags(x, model, lb, vec, sw):\r\n",
    "    x_clean = text_treatment(str(x), sw)\r\n",
    "    x_vec = vectorize(x_clean, vec)\r\n",
    "    return get_best_tags(model, x_vec, lb)\r\n",
    "\r\n",
    "treat_text_get_tags(x, model, lb, vec, sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\r\n",
    "# 6. Interpretation et conclusion\r\n",
    "<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Sommaire</a>\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats obtenus semblent pertinent dans leur contexte.  \r\n",
    "Néanmoins ils sont souvent différents de ceux prédit par Stackoverflow.\r\n",
    "\r\n",
    "Un grand nombre d'hyperparamètres peuvent permettrent d'améliorer le modèle sélectionné pour s'approcher d'avantage des étiquettes du site.\r\n",
    "\r\n",
    "Notre approche ne permet cependant pas d'ajouter de nouveaux tags au fur et à mesure des nouvelles questions.  \r\n",
    "Il sera pour cela nécessaire de réentrainer un modèle.\r\n",
    "\r\n",
    "De plus il serait pertinent d'utiliser des dictionnaires spécifiques au domaine pour gagner en précision.\r\n",
    "Cela permettrait par exemple de traiter correctement des mots comme \"R, c, pandas, etc.\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5594ac13a64e2174d726a1d0fdcbb64a3f91b0663c1999d89a89d2456ad9a960"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('env_p5': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}